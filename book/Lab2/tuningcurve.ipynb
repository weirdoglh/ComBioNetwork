{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/weirdoglh/ComBioNetwork/blob/main/book/Lab2/tuningcurve.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mPZ4suK5OgJ"
      },
      "source": [
        "# Tuning curve, encoding, and decoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "bT9SPEg55IoV",
        "tags": [
          "hide-input"
        ]
      },
      "outputs": [],
      "source": [
        "#@title Run the following to initialize lab environment.\n",
        "\n",
        "!pip install ipympl ipywidgets stg-net scipy -q\n",
        "\n",
        "import matplotlib.pyplot as plt         # import matplotlib\n",
        "from matplotlib.widgets import Slider\n",
        "import numpy as np                      # import numpy\n",
        "import scipy\n",
        "import ipywidgets as widgets            # interactive display\n",
        "\n",
        "# Colab setting for widget\n",
        "try:\n",
        "    from google.colab import output\n",
        "    output.enable_custom_widget_manager()\n",
        "except ImportError:\n",
        "    pass\n",
        "\n",
        "# modeling library\n",
        "from stg_net.neuron import LIF\n",
        "from stg_net.input import Poisson_generator, Gaussian_generator, Current_injector\n",
        "from stg_net.conn import Simulator\n",
        "from stg_net.helper import plot_volt_trace\n",
        "\n",
        "# setting for figures\n",
        "fig_w, fig_h = 8, 6\n",
        "my_fontsize = 18\n",
        "my_params = {'axes.labelsize': my_fontsize,\n",
        "          'axes.titlesize': my_fontsize,\n",
        "          'figure.figsize': (fig_w, fig_h),\n",
        "          'font.size': my_fontsize,\n",
        "          'legend.fontsize': my_fontsize-4,\n",
        "          'lines.markersize': 8.,\n",
        "          'lines.linewidth': 2.,\n",
        "          'xtick.labelsize': my_fontsize-2,\n",
        "          'ytick.labelsize': my_fontsize-2}\n",
        "plt.rcParams.update(my_params)\n",
        "my_layout = widgets.Layout()\n",
        "\n",
        "# Auto Reloading\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "# Widget interaction\n",
        "%matplotlib widget"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZ33p5-JOBG6"
      },
      "source": [
        "## Tuning Curves of Neurons\n",
        "\n",
        "Consider a situation in which **N neurons** project onto a single **target neuron**. Each of the input neurons is tuned to a specific input â€” for example, the **orientation of a moving bar**.\n",
        "\n",
        "When the input weights are carefully chosen, we can make the target neuron **sensitive to a narrow range of input orientations**. This selective sensitivity, or **tuning**, is a hallmark of **early sensory representation in the neocortex**.\n",
        "\n",
        "Moreover, we can use this tuning property of neurons to **decode the input**, providing insight into how neural populations represent sensory information.\n",
        "\n",
        "### Exercise Overview\n",
        "\n",
        "In this exercise, you will:\n",
        "\n",
        "1. **Manually adjust the input weights** to tune a single neuron to a range of input stimuli.\n",
        "2. Use **Hebbian plasticity** to **learn the input weights** automatically.\n",
        "\n",
        "This hands-on approach will help illustrate how tuning emerges both through design and learning in neural systems.\n",
        "\n",
        "\n",
        "<img src=\"https://github.com/weirdoglh/ComBioNetwork/blob/main/book/Lab2/sensory-encoding.PNG?raw=true\" alt=\"Encoding network\" width=\"1000\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "W1PHVnstOBG7",
        "tags": [
          "hide-input"
        ]
      },
      "outputs": [],
      "source": [
        "#@title Run the following to manipulate tuning curve { vertical-output: true }\n",
        "T, dt = 3e2, 0.1        # simulation period(ms), step size(ms)\n",
        "N = 10              # number of neurons\n",
        "\n",
        "tonic_neuron = {'tau_m':20., 'a':0., 'tau_w':30., 'b':3., 'V_reset':-55.}\n",
        "adapting_neuron = {'tau_m':20., 'a':0., 'tau_w':100., 'b':0.5, 'V_reset':-55.}\n",
        "initburst_neuron = {'tau_m':10., 'a':0., 'tau_w':100., 'b':1., 'V_reset':-50.}\n",
        "bursting_neuron = {'tau_m':5., 'a':0., 'tau_w':100., 'b':1., 'V_reset':-46.}\n",
        "irregular_neuron = {'tau_m':10., 'a':-0.01, 'tau_w':50., 'b':1.2, 'V_reset':-46.}\n",
        "transient_neuron = {'tau_m':5., 'a':0.05, 'tau_w':100., 'b':0.7, 'V_reset':-60.}\n",
        "delayed_neuron = {'tau_m':5., 'a':-0.1, 'tau_w':100., 'b':1., 'V_reset':-60.}\n",
        "\n",
        "neuron_params = {'tonic_neuron': tonic_neuron, 'adapting_neuron': adapting_neuron,\n",
        "                 'initburst_neuron': initburst_neuron, 'bursting_neuron': bursting_neuron,\n",
        "                 'irregular_neuron': irregular_neuron, 'transient_neuron': transient_neuron,\n",
        "                 'delayed_neuron': delayed_neuron, 'my_neuron': tonic_neuron}\n",
        "\n",
        "# inputs\n",
        "ms, xs = np.linspace(0., 1., 101), np.linspace(0.05-1e-5, 0.95-1e-5, N)\n",
        "rins = [np.array([max(scipy.stats.norm(mean, 0.1).pdf([x, x-1, 1+x]))  for x in xs]) for mean in ms]\n",
        "\n",
        "# weights\n",
        "grid = widgets.GridspecLayout(2, N+2)\n",
        "wsize = '200px'\n",
        "for i, label in enumerate(['location','spread'] + ['J_o%d'%i for i in np.arange(1, N+1)]):\n",
        "    grid[0, i] = widgets.Text(value=label, disabled=True, layout=widgets.Layout(width=wsize))\n",
        "for i in np.arange(2, N+2):\n",
        "    grid[1, i] = widgets.FloatSlider(value=0.2, min=0.0, max=0.4, step=0.01, layout=widgets.Layout(width=wsize))\n",
        "grid[1, 0] = widgets.FloatSlider(value=5, min=0, max=10, step=0.1, layout=widgets.Layout(width=wsize))\n",
        "grid[1, 1] = widgets.FloatSlider(value=1, min=0, max=2, step=0.1, layout=widgets.Layout(width=wsize))\n",
        "\n",
        "con_bars = {}\n",
        "con_bars['mean'] = grid[1, 0]\n",
        "con_bars['std'] = grid[1, 1]\n",
        "for i in np.arange(1, N+1):\n",
        "    con_bars['J_o%d'%i] = grid[1, i+1]\n",
        "\n",
        "# updating parameters\n",
        "def update_tune(**con_dict):\n",
        "    # simualtor\n",
        "    h = Simulator(dt=dt)\n",
        "\n",
        "    # network of neurons\n",
        "    nrns = [LIF(sim=h) for _ in range(N)]\n",
        "    for nrn in nrns:\n",
        "        nrn.update(tonic_neuron)\n",
        "\n",
        "    # input and weights\n",
        "    cons = np.array(list(con_dict.values()), dtype=float)\n",
        "    mean, std, ws = cons[0]/10, cons[1]/10, cons[2:]\n",
        "\n",
        "    # background noise\n",
        "    rdist = [max(scipy.stats.norm(mean, std).pdf([x, x-1, 1+x])) for x in xs]\n",
        "    rs = np.array([0.5] + rdist)*1e2\n",
        "    noises = [Poisson_generator(sim=h, rate=r*3, start=0, end=int(T/dt)) for r in rs]\n",
        "    for noise, nrn in zip(noises, nrns):\n",
        "        nrn.connect(noise, {'ctype':'Static', 'weight':1e0, 'delay':5})\n",
        "\n",
        "    # recurrent connections\n",
        "    tps = [['Static' for _ in range(N)] for _ in range(N)]\n",
        "    con = np.zeros((N,N))\n",
        "    con[0] = ws * 5\n",
        "    dly = np.random.uniform(2., 5., (N,N))\n",
        "    synspecs = [[{} for _ in range(N)] for _ in range(N)]\n",
        "    for i in range(N):\n",
        "        for j in range(N):\n",
        "            synspecs[i][j] = {'ctype':tps[i][j], 'weight':con[i,j], 'delay':dly[i,j]}\n",
        "    h.connect(nrns, nrns, synspecs)\n",
        "\n",
        "    # simulation\n",
        "    h.run(T)\n",
        "\n",
        "    # save weight\n",
        "    ys = np.array([np.dot(ws, rin) for rin in rins])\n",
        "\n",
        "    # visualize\n",
        "    plt.clf()\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.title('raster')\n",
        "    for nrn, l in zip(nrns, range(N)):\n",
        "        if l == 0:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='r', lineoffsets=l, linelengths=0.4, label='%.1fHz'%(len(nrn.spikes['times'])/T*1e3*2))\n",
        "        else:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='b', lineoffsets=l, linelengths=0.4, label='%.1fHz'%(len(nrn.spikes['times'])/T*1e3*2))\n",
        "    plt.xlabel('time(ms)')\n",
        "    plt.yticks(list(np.arange(N+1)), ['out'] + list(np.arange(1, N+1)))\n",
        "    plt.ylabel('nrn idx')\n",
        "    plt.xlim([0., T])\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.title('tuning curve')\n",
        "    plt.plot(ms, ys)\n",
        "    plt.xlabel('location')\n",
        "    plt.xticks(list(np.arange(N+1)/10), list(np.arange(N+1)))\n",
        "    plt.ylabel('response level')\n",
        "    plt.ylim([0, 3.5])\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "try:\n",
        "    plt.figure(fig_tune)\n",
        "    plt.clf()\n",
        "except:\n",
        "    ...\n",
        "fig_tune, axes = plt.subplots(1,2,figsize=(10,5))\n",
        "widget_tune = widgets.interactive_output(update_tune, con_bars);\n",
        "display(grid, widget_tune);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yizMU84fLpzT"
      },
      "source": [
        "## To do\n",
        "\n",
        "Try to change the feed-forward synaptic weights to have an output neuron with arbitrary tuning curve."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "GGAyIyqWOBG7",
        "tags": [
          "hide-input"
        ]
      },
      "outputs": [],
      "source": [
        "#@title Run the following to start competitive learning, when output neuron spikes all synapses change plasticity according to their local activity.  { vertical-output: true }\n",
        "T, dt = 3e2, 0.1        # simulation period(ms), step size(ms)\n",
        "\n",
        "# output neurons\n",
        "out_labels = ['a', 'b']\n",
        "M = len(out_labels)     # number of cells\n",
        "N = 10           # number of neurons\n",
        "\n",
        "# inputs\n",
        "std_low, std_high = 0.02, 0.2\n",
        "ms, ss, xs = np.linspace(0., 1., 11), np.linspace(std_low, std_high, 11), np.linspace(0.05-1e-5, 0.95-1e-5, N)\n",
        "rins = np.array([[[max(scipy.stats.norm(mean, std).pdf([x, x-1, 1+x])) for x in xs] for std in ss] for mean in ms])\n",
        "\n",
        "# weights\n",
        "ws = np.ones((M, N)) * 0.25\n",
        "\n",
        "# outputs\n",
        "ys = np.zeros((M, len(ms), len(ss)))\n",
        "\n",
        "# recordings\n",
        "samples = []\n",
        "responses = []\n",
        "\n",
        "# updating parameters\n",
        "def update_comp(mean=0.5, std=0.1,  Target_Output_Neuron='a', plasticity=False):\n",
        "    nIdx = out_labels.index(Target_Output_Neuron)\n",
        "    # simualtor\n",
        "    h = Simulator(dt=dt)\n",
        "\n",
        "    # network of neurons\n",
        "    nrns = [LIF(sim=h) for _ in range(M+N)]\n",
        "    for nrn in nrns:\n",
        "        nrn.update(tonic_neuron)\n",
        "\n",
        "    # background noise\n",
        "    rdist = [max(scipy.stats.norm(mean, std).pdf([x, x-1, 1+x])) for x in xs]\n",
        "    rs = np.array([0.5]*M + rdist)*1e3/np.sum(rdist)\n",
        "    noises = [Poisson_generator(sim=h, rate=r*3, start=0, end=int(T/dt)) for r in rs]\n",
        "    for noise, nrn in zip(noises, nrns):\n",
        "        nrn.connect(noise, {'ctype':'Static', 'weight':1e0, 'delay':5})\n",
        "\n",
        "    # recurrent connections\n",
        "    tps = [['Static' for _ in range(M+N)] for _ in range(M+N)]\n",
        "    if plasticity:\n",
        "        for i in np.arange(N):\n",
        "            tps[nIdx][i+M] = 'Comp'\n",
        "    con = np.zeros((M+N, M+N))\n",
        "    global ws\n",
        "    for i in range(M):\n",
        "        con[i, M:] = ws[i]\n",
        "    dly = np.random.uniform(2., 5., (M+N, M+N))\n",
        "    synspecs = [[{} for _ in range(M+N)] for _ in range(M+N)]\n",
        "    for i in range(M+N):\n",
        "        for j in range(M+N):\n",
        "            synspecs[i][j] = {'ctype':tps[i][j], 'weight':con[i,j], 'delay':dly[i,j]}\n",
        "    cons = h.connect(nrns, nrns, synspecs)\n",
        "\n",
        "    # simulation\n",
        "    h.run(T)\n",
        "\n",
        "    # save weight\n",
        "    global samples\n",
        "    global responses\n",
        "    if plasticity:\n",
        "        ws[nIdx] = np.array([cons[nIdx][i+M].weights[-1] for i in np.arange(0, N)])\n",
        "        samples = []\n",
        "        responses = []\n",
        "\n",
        "    # update tuning curve\n",
        "    global ys\n",
        "    for k in range(M):\n",
        "        for i in range(len(ms)):\n",
        "            for j in range(len(ss)):\n",
        "                ys[k, i, j] = np.dot(ws[k], rins[i,j])\n",
        "\n",
        "    # collect samples\n",
        "    if not plasticity:\n",
        "        samples.append([mean, std])\n",
        "        responses.append([len(nrns[i].spikes['times']) for i in range(M)])\n",
        "\n",
        "# visualize\n",
        "    plt.clf()\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(12, 18)  # Increase figure size (width, height)\n",
        "\n",
        "    plt.subplot(3, 2, 1)\n",
        "    plt.title('raster', fontsize=16)  # Increase title font size\n",
        "    for nrn, l in zip(nrns, range(M + N)):\n",
        "        if l < M:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='r', lineoffsets=l, linelengths=0.4,\n",
        "                          label='%.1fHz' % (len(nrn.spikes['times']) / T * 1e3 * 2))\n",
        "        else:\n",
        "            plt.eventplot(nrn.spikes['times'], colors='b', lineoffsets=l, linelengths=0.4,\n",
        "                          label='%.1fHz' % (len(nrn.spikes['times']) / T * 1e3 * 2))\n",
        "    plt.xlabel('time(ms)', fontsize=14)  # Increase axis label font size\n",
        "    plt.yticks(list(np.arange(M + N)), out_labels + list(np.arange(1, N + 1)), fontsize=12)  # Increase tick label font size\n",
        "    plt.ylabel('nrn idx', fontsize=14)  # Increase axis label font size\n",
        "    plt.xlim([0., T])\n",
        "    plt.legend(fontsize=10)  # Add legend and adjust font size\n",
        "\n",
        "    plt.subplot(3, 2, 2)\n",
        "    plt.title('synaptic weights', fontsize=16)  # Increase title font size\n",
        "    if plasticity:\n",
        "        weights = np.array([cons[nIdx][i + M].weights for i in np.arange(0, N)])\n",
        "        plt.imshow(weights[:, np.arange(0, int(T / dt), 100)], extent=[0, T, 1, 10], origin='lower', aspect=30)\n",
        "    else:\n",
        "        plt.imshow(np.tile(ws[nIdx], (int(T / dt / 100), 1)).T, extent=[0, T, 1, 10], origin='lower', aspect=30)\n",
        "    plt.xlabel('time(ms)', fontsize=14)  # Increase axis label font size\n",
        "    plt.ylabel('syn Idx', fontsize=14)  # Increase axis label font size\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.ax.tick_params(labelsize=12)  # Increase colorbar tick label font size\n",
        "\n",
        "    plt.subplot(3, 2, 3)\n",
        "    plt.title('tuning curve a', fontsize=16)  # Increase title font size\n",
        "    plt.imshow(ys[0], extent=[std_low, std_high, 0., 1.0], origin='lower', aspect=std_high - std_low)\n",
        "    plt.xlabel('std', fontsize=14)  # Increase axis label font size\n",
        "    plt.ylabel('mean', fontsize=14)  # Increase axis label font size\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.ax.tick_params(labelsize=12)  # Increase colorbar tick label font size\n",
        "\n",
        "    plt.subplot(3, 2, 4)\n",
        "    plt.title('tuning curve b', fontsize=16)  # Increase title font size\n",
        "    plt.imshow(ys[1], extent=[std_low, std_high, 0., 1.0], origin='lower', aspect=std_high - std_low)\n",
        "    plt.xlabel('std', fontsize=14)  # Increase axis label font size\n",
        "    plt.ylabel('mean', fontsize=14)  # Increase axis label font size\n",
        "    cbar = plt.colorbar()\n",
        "    cbar.ax.tick_params(labelsize=12)  # Increase colorbar tick label font size\n",
        "\n",
        "    plt.subplot(3, 2, 5)\n",
        "    plt.title('input patterns', fontsize=16)  # Increase title font size\n",
        "    if len(samples) > 0:\n",
        "        plt.scatter(np.array(samples)[:, 0], np.array(samples)[:, 1], c=range(len(samples)))\n",
        "    plt.xlabel('mean', fontsize=14)  # Increase axis label font size\n",
        "    plt.ylabel('std', fontsize=14)  # Increase axis label font size\n",
        "    plt.xlim([0., 1.])\n",
        "    plt.ylim([std_low, std_high])\n",
        "\n",
        "    plt.subplot(3, 2, 6)\n",
        "    plt.title('output responses', fontsize=16)  # Increase title font size\n",
        "    if len(responses) > 0:\n",
        "        plt.scatter(np.array(responses)[:, 0], np.array(responses)[:, 1], c=range(len(responses)))\n",
        "    plt.xlabel('a(spikes)', fontsize=14)  # Increase axis label font size\n",
        "    plt.ylabel('b(spikes)', fontsize=14)  # Increase axis label font size\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "try:\n",
        "    plt.figure(fig_comp)\n",
        "    plt.clf()\n",
        "except:\n",
        "    ...\n",
        "fig_comp, axes = plt.subplots(3,2,figsize=(10,10))\n",
        "widgets.interact(update_comp, mean=(0., 1.0, 0.01), std=(std_low, std_high, 0.02), Target_Output_Neuron=out_labels, plasticity=[True, False]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EdbkG6aHL7xC"
      },
      "source": [
        "## To-Do: Train Two Neurons with Plasticity\n",
        "\n",
        "We're going to work with two simulated neurons, let's call them Neuron A and Neuron B. Instead of us telling them how to react (setting weights manually), we'll let them learn from the signals they receive â€“ this is what \"plastic synapses\" allow.\n",
        "\n",
        "**Here's what you need to do:**\n",
        "\n",
        "1.  **Training Phase (Plasticity ON):**\n",
        "    * Expose Neuron A and Neuron B to different input signals (stimuli).\n",
        "    * Because their synapses are \"plastic,\" they will change how they respond to these signals over time, developing their own unique \"preferences\" or \"tuning curves.\" Think of it like each neuron becoming particularly sensitive to a specific range of inputs.\n",
        "\n",
        "2.  **Testing Phase (Plasticity OFF):**\n",
        "    * Once they've learned (their tuning curves have developed), we'll turn off their ability to change (turn off plasticity).\n",
        "    * Now, we'll present a new set of input signals to both Neuron A and Neuron B.\n",
        "    * For each input signal, we'll record how strongly each neuron fires (their \"firing rate\"). This combined response of both neurons to each signal is what we're interested in.\n",
        "\n",
        "## Think:\n",
        "\n",
        "* **Decoding Information with Two Neurons:**\n",
        "    * Imagine you only have the firing rates of Neuron A and Neuron B. Do you think you can figure out both the *average* (mean) and the *spread* (standard deviation) of the original input signal that caused those firing rates?\n",
        "    * If you think two neurons aren't enough, how many more might you need and why? What kind of information is potentially lost with only two?\n",
        "\n",
        "* **Figuring Out the Input:**\n",
        "    * If you have the firing rates of Neuron A and Neuron B for a particular input signal, how would you go about using those firing rates to estimate what the original input signal was? (Think about how their tuning curves relate to their firing rates.)\n",
        "\n",
        "* **Designing Good Tuning Curves:**\n",
        "    * Let's say you could design the \"ideal\" tuning curves for Neuron A and Neuron B to help you best decode both the mean and the standard deviation of the input. Consider these options for their tuning curves:\n",
        "        * **Overlap:** Should their preferred input ranges be similar (overlapping) or different (non-overlapping)? What are the advantages and disadvantages of each?\n",
        "        * **Width:** Should their tuning curves be broad (respond to a wide range of inputs) or narrow (respond to a very specific range)? What are the trade-offs?\n",
        "        * **Shape:** Should they have a single peak in their response or multiple peaks? Why might one be better than the other for decoding mean and standard deviation?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "9914d6bfacb954328c3ffb911a6400e44a72a30de8da69be678e590a88116170"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('base': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}